{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11178952,"sourceType":"datasetVersion","datasetId":6977462},{"sourceId":10716,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8658,"modelId":1445}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:32:46.594681Z","iopub.execute_input":"2025-03-29T11:32:46.594883Z","iopub.status.idle":"2025-03-29T11:32:46.939255Z","shell.execute_reply.started":"2025-03-29T11:32:46.594864Z","shell.execute_reply":"2025-03-29T11:32:46.938392Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/phi/transformers/2/1/model.safetensors.index.json\n/kaggle/input/phi/transformers/2/1/CODE_OF_CONDUCT.md\n/kaggle/input/phi/transformers/2/1/config.json\n/kaggle/input/phi/transformers/2/1/modeling_phi.py\n/kaggle/input/phi/transformers/2/1/merges.txt\n/kaggle/input/phi/transformers/2/1/model-00001-of-00002.safetensors\n/kaggle/input/phi/transformers/2/1/LICENSE\n/kaggle/input/phi/transformers/2/1/model-00002-of-00002.safetensors\n/kaggle/input/phi/transformers/2/1/configuration_phi.py\n/kaggle/input/phi/transformers/2/1/SECURITY.md\n/kaggle/input/phi/transformers/2/1/tokenizer.json\n/kaggle/input/phi/transformers/2/1/vocab.json\n/kaggle/input/phi/transformers/2/1/tokenizer_config.json\n/kaggle/input/phi/transformers/2/1/special_tokens_map.json\n/kaggle/input/phi/transformers/2/1/.gitattributes\n/kaggle/input/phi/transformers/2/1/NOTICE.md\n/kaggle/input/phi/transformers/2/1/added_tokens.json\n/kaggle/input/phi/transformers/2/1/generation_config.json\n/kaggle/input/tomoro-ai/combined.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q -U bitsandbytes transformers peft accelerate datasets trl\n!pip install -q -U huggingface_hub einops","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:32:50.741777Z","iopub.execute_input":"2025-03-29T11:32:50.742117Z","iopub.status.idle":"2025-03-29T11:33:11.629431Z","shell.execute_reply.started":"2025-03-29T11:32:50.742089Z","shell.execute_reply":"2025-03-29T11:33:11.628582Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    TrainingArguments,\n    BitsAndBytesConfig\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:33:14.236389Z","iopub.execute_input":"2025-03-29T11:33:14.236691Z","iopub.status.idle":"2025-03-29T11:33:22.401791Z","shell.execute_reply.started":"2025-03-29T11:33:14.236666Z","shell.execute_reply":"2025-03-29T11:33:22.401131Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!python -m pip install -U peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:33:33.810370Z","iopub.execute_input":"2025-03-29T11:33:33.810874Z","iopub.status.idle":"2025-03-29T11:33:37.329050Z","shell.execute_reply.started":"2025-03-29T11:33:33.810848Z","shell.execute_reply":"2025-03-29T11:33:37.328189Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.50.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.5.2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft) (2024.12.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->peft) (2024.2.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from peft import LoraConfig, prepare_model_for_kbit_training\nfrom trl import SFTTrainer\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:33:47.627649Z","iopub.execute_input":"2025-03-29T11:33:47.627981Z","iopub.status.idle":"2025-03-29T11:34:01.931001Z","shell.execute_reply.started":"2025-03-29T11:33:47.627956Z","shell.execute_reply":"2025-03-29T11:34:01.930376Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tomoro-ai/combined.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:34:04.989299Z","iopub.execute_input":"2025-03-29T11:34:04.989600Z","iopub.status.idle":"2025-03-29T11:34:05.230917Z","shell.execute_reply.started":"2025-03-29T11:34:04.989577Z","shell.execute_reply":"2025-03-29T11:34:05.230010Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:34:12.142910Z","iopub.execute_input":"2025-03-29T11:34:12.143241Z","iopub.status.idle":"2025-03-29T11:34:12.167449Z","shell.execute_reply.started":"2025-03-29T11:34:12.143217Z","shell.execute_reply":"2025-03-29T11:34:12.166748Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                           Question  Answer  \\\n0           0  what was the percentage change in the net cash...   14.1%   \n1           1  what was the percentage change in net sales fr...    -32%   \n2           2  what portion of the total shares subject to ou...   70.1%   \n3           3  what was the percent of the change in the comp...   15.7%   \n4           4  what portion of total obligations are due with...  22.99%   \n\n                                        Program  \\\n0  subtract(206588, 181001), divide(#0, 181001)   \n1        subtract(5363, 7983), divide(#0, 7983)   \n2    add(2530454, 5923147), divide(5923147, #0)   \n3           subtract(118, 102), divide(#0, 102)   \n4         add(27729, 45161), divide(#0, 317105)   \n\n                                           Processed  \n0  Question: what was the percentage change in th...  \n1  Question: what was the percentage change in ne...  \n2  Question: what portion of the total shares sub...  \n3  Question: what was the percent of the change i...  \n4  Question: what portion of total obligations ar...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Question</th>\n      <th>Answer</th>\n      <th>Program</th>\n      <th>Processed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>what was the percentage change in the net cash...</td>\n      <td>14.1%</td>\n      <td>subtract(206588, 181001), divide(#0, 181001)</td>\n      <td>Question: what was the percentage change in th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>what was the percentage change in net sales fr...</td>\n      <td>-32%</td>\n      <td>subtract(5363, 7983), divide(#0, 7983)</td>\n      <td>Question: what was the percentage change in ne...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>what portion of the total shares subject to ou...</td>\n      <td>70.1%</td>\n      <td>add(2530454, 5923147), divide(5923147, #0)</td>\n      <td>Question: what portion of the total shares sub...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>what was the percent of the change in the comp...</td>\n      <td>15.7%</td>\n      <td>subtract(118, 102), divide(#0, 102)</td>\n      <td>Question: what was the percent of the change i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>what portion of total obligations are due with...</td>\n      <td>22.99%</td>\n      <td>add(27729, 45161), divide(#0, 317105)</td>\n      <td>Question: what portion of total obligations ar...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"model_name = \"/kaggle/input/phi/transformers/2/1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:34:18.747110Z","iopub.execute_input":"2025-03-29T11:34:18.747411Z","iopub.status.idle":"2025-03-29T11:34:18.751302Z","shell.execute_reply.started":"2025-03-29T11:34:18.747391Z","shell.execute_reply":"2025-03-29T11:34:18.750278Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# 4-bit quantization config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:34:25.164822Z","iopub.execute_input":"2025-03-29T11:34:25.165281Z","iopub.status.idle":"2025-03-29T11:34:25.171476Z","shell.execute_reply.started":"2025-03-29T11:34:25.165240Z","shell.execute_reply":"2025-03-29T11:34:25.170575Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)  # Should output 4.38.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:34:35.069410Z","iopub.execute_input":"2025-03-29T11:34:35.069711Z","iopub.status.idle":"2025-03-29T11:34:35.074193Z","shell.execute_reply.started":"2025-03-29T11:34:35.069688Z","shell.execute_reply":"2025-03-29T11:34:35.073298Z"}},"outputs":[{"name":"stdout","text":"4.50.3\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Load model and tokenizer\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n).to(\"cuda\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:37:18.064405Z","iopub.execute_input":"2025-03-29T11:37:18.064733Z","iopub.status.idle":"2025-03-29T11:37:20.831725Z","shell.execute_reply.started":"2025-03-29T11:37:18.064709Z","shell.execute_reply":"2025-03-29T11:37:20.831094Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba0eeaf6df5f498689a2273ddda8d789"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:37:34.114950Z","iopub.execute_input":"2025-03-29T11:37:34.115319Z","iopub.status.idle":"2025-03-29T11:37:34.260638Z","shell.execute_reply.started":"2025-03-29T11:37:34.115292Z","shell.execute_reply":"2025-03-29T11:37:34.259958Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Prepare model for training\nmodel = prepare_model_for_kbit_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:37:46.909568Z","iopub.execute_input":"2025-03-29T11:37:46.909888Z","iopub.status.idle":"2025-03-29T11:37:46.936117Z","shell.execute_reply.started":"2025-03-29T11:37:46.909869Z","shell.execute_reply":"2025-03-29T11:37:46.935434Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=128,\n    lora_alpha=128,\n    lora_dropout=0.01,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]  # Apply LoRA to more layers\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:37:52.920219Z","iopub.execute_input":"2025-03-29T11:37:52.920514Z","iopub.status.idle":"2025-03-29T11:37:52.924531Z","shell.execute_reply.started":"2025-03-29T11:37:52.920480Z","shell.execute_reply":"2025-03-29T11:37:52.923594Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#%% [Training Arguments]\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=20,\n    per_device_train_batch_size=2,  # Reduce if OOM occurs\n    gradient_accumulation_steps=2,\n    learning_rate=1e-3,\n    fp16=True,\n    logging_steps=10,\n    optim=\"paged_adamw_8bit\",\n    save_strategy=\"steps\",\n    save_steps=250,\n    save_total_limit=1,  # Keep only the latest model, replacing the previous one\n    report_to=\"none\",\n    max_grad_norm=0.3,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"cosine\",\n    dataloader_pin_memory=True,  # GPU memory optimization\n\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:38:00.340407Z","iopub.execute_input":"2025-03-29T11:38:00.340720Z","iopub.status.idle":"2025-03-29T11:38:00.368659Z","shell.execute_reply.started":"2025-03-29T11:38:00.340698Z","shell.execute_reply":"2025-03-29T11:38:00.367991Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:39:38.061153Z","iopub.execute_input":"2025-03-29T11:39:38.061560Z","iopub.status.idle":"2025-03-29T11:39:38.178516Z","shell.execute_reply.started":"2025-03-29T11:39:38.061533Z","shell.execute_reply":"2025-03-29T11:39:38.177819Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#%% [Initialize Trainer]\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    # dataset_text_field='Processed',\n    # max_seq_length=2048,  # Reduce based on your context length\n    # tokenizer=tokenizer,\n    formatting_func=lambda example: example[\"Processed\"],\n    args=training_args,\n    # packing=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:39:40.113253Z","iopub.execute_input":"2025-03-29T11:39:40.113553Z","iopub.status.idle":"2025-03-29T11:39:48.977569Z","shell.execute_reply.started":"2025-03-29T11:39:40.113530Z","shell.execute_reply":"2025-03-29T11:39:48.976707Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Applying formatting function to train dataset:   0%|          | 0/2234 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06a50c7e24704b3fbea594b410f5270e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/2234 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b111e9c1bae94f0da6a4a1827cd7b60d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/2234 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5272b19cb7264c32a3e2568fd089a30a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/2234 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a86bbd7193446bfb127ed4b739704fe"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (2688 > 2048). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/2234 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a08c9043ee471a954d78a7a81da44f"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"#%% [Start Training]\ntrainer.train()\n\n#%% [Save Adapter]\ntrainer.save_model(\"final_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T11:39:52.952195Z","iopub.execute_input":"2025-03-29T11:39:52.952493Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='11160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   60/11160 11:48 < 37:38:35, 0.08 it/s, Epoch 0.11/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.036900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.951900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.892500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.758700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.791800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}